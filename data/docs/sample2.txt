Retrieval augmented generation, or RAG, is a pattern where a language model is given
external context that is retrieved based on the user's query. This helps ground the
model's responses in the retrieved documents and reduces hallucinations.

In this project, all inference is done via a local Ollama model, with no external APIs.
